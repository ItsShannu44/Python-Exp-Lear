from urllib.request import urlopen
from bs4 import BeautifulSoup as bs
import pandas as pd
import re
 
#   Url which contains data
url="https://tatamumbaimarathon.procam.in/results/race-results"

#   pass url to urlopen() to get html of page
html=urlopen(url)
print(type(html),html)

#   construct BeautifulSoup obj using the html
soup=bs(html,'lxml')

# Extract teh title of the Webpage
title=soup.title
print(title)
print(type(title))

# Extract the text of the webpage
text=soup.get_text()
print(soup.text,type(text))
print("\n \n")
# print(text,type(text)) #both are same res

#   Extract the useful html tags within the page

soup.find_all('a')

#   Print the hyperlinks
all_links=soup.find_all('a')
for link in all_links:
    print(link.get('href'))

#   Extract tabular data
rows=soup.find_all('tr')
print(rows)
print("\n")
print(type(rows))

#   Get all table rows in a list form and convert into a DF
for row in rows:
    row_td=row.find_all('td')
print(row_td)
print("\n\n")
print(type(row_td))

#   Extract the data without the html tags
str_cell=str(row_td)
cleantext=bs(str_cell, 'lxml').get_text()
print(cleantext)
print("\n\n")
print(type(cleantext))

#   Extract the Data without html tags using regex
list_row=[]
for row in rows:
    cells=row.find_all('td')
    str_cell=str(cells)
    clean=re.compile('<.*?>')
    clean_l=(re.sub(clean,'',str_cell))
    list_row.append(clean_l)
    print(list_row)

df=pd.DataFrame(list_row)
print(df.head(10))

#   Data Manipulation and Cleaning
df1=df[0].str.split(',',expand=True)
print(df1.head(5))

# Remove the opening square braces
df1[0]=df1[0].str.strip('[')
print(df1.head(5))

df1[4]=df1[4].str.strip(']')
print(df1.head(5))

#   Accessing the title for the cols
col_labels=soup.find_all('th')
print(col_labels)
print('\n\n')
print(type(col_labels))
all_head=[]
col_str=str(col_labels)
clean_text=bs(col_str,'lxml').get_text() #Removes all the tags from the text
all_head.append(clean_text)
print(all_head)

#   convert to df
df2=pd.DataFrame(all_head)
print(df2)
#splitting
df3=df2[0].str.split(',',expand=True)
print(df3.head(5))
# Remove the opening square braces
df3[0]=df3[0].str.strip('[')
df3[4]=df3[4].str.strip(']')
print(df3.head(5))
print("\n\n")

#--------MERGE THE TWO DF------------
frames=[df3,df1]
df4=pd.concat(frames)
print(df4.head(5))

# -- Assign the 1st row to be the table header
df5=df4.rename(columns=df4.iloc[0])
print(df5.head(5))

#---Drop all rows with missing vals
df5=df5.dropna(axis=0,how='any')
print(df5.head(5))

#---Drop row 0
df5=df5.drop(index=0)
print(df5.head(5))
print("\n")
df5.info()
print(df5.shape)

#____Processing of DF_________

#a. convert the finish time to total no of minutes.

# Convert Finish Time (HH:MM:SS) to total minutes

#add the new col as run_mins
